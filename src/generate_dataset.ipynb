{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings)\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "tfback._get_available_gpus()\n",
    "tf.config.list_logical_devices()\n",
    "import keras\n",
    "from keras import backend\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_spots(path , lower_range , higher_range):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img , (768,512))\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_range, higher_range)\n",
    "    mask  = cv2.morphologyEx(cv2.medianBlur(mask , 3) , cv2.MORPH_CLOSE, np.ones((3,3) , np.uint8))\n",
    "    res = cv2.bitwise_and(img , img , mask = mask)\n",
    "    return mask , res\n",
    "\n",
    "def add_spots(path , mask , spots):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img , (768,512))\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    img_bg = cv2.bitwise_and(img , img , mask = mask_inv)\n",
    "    img_new = cv2.add(img_bg , spots)\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_mask(mask , spots):\n",
    "    w = np.random.randint(mask.shape[1])\n",
    "    h = np.random.randint(mask.shape[0])\n",
    "    x = np.random.randint(mask.shape[1] - w)\n",
    "    y = np.random.randint(mask.shape[0] - h)\n",
    "    new_mask = new_mask[y:y+h , x:x+w]\n",
    "    new_mask = cv2.resize(new_mask , (768,512))\n",
    "    new_spots = new_spots[y:y+h , x:x+w]\n",
    "    new_spots = cv2.resize(new_spots , (768,512))\n",
    "    return new_mask , new_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nst(content , style):\n",
    "    \n",
    "    CHANNELS = 3\n",
    "    IMAGE_SIZE = 500\n",
    "    IMAGE_WIDTH = 768\n",
    "    IMAGE_HEIGHT = 512\n",
    "    IMAGENET_MEAN_RGB_VALUES = [123.68, 116.779, 103.939]\n",
    "    CONTENT_WEIGHT = 0.02\n",
    "    STYLE_WEIGHT = 4.5\n",
    "    TOTAL_VARIATION_WEIGHT = 0.995\n",
    "    TOTAL_VARIATION_LOSS_FACTOR = 1.25\n",
    "    \n",
    "    def content_loss(content, combination):\n",
    "        return backend.sum(backend.square(combination - content))\n",
    "\n",
    "    def gram_matrix(x):\n",
    "        features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
    "        gram = backend.dot(features, backend.transpose(features))\n",
    "        return gram\n",
    "\n",
    "    def compute_style_loss(style, combination):\n",
    "        style = gram_matrix(style)\n",
    "        combination = gram_matrix(combination)\n",
    "        size = IMAGE_HEIGHT * IMAGE_WIDTH\n",
    "        return backend.sum(backend.square(style - combination)) / (4. * (CHANNELS ** 2) * (size ** 2))\n",
    "\n",
    "    def total_variation_loss(x):\n",
    "        a = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, 1:, :IMAGE_WIDTH-1, :])\n",
    "        b = backend.square(x[:, :IMAGE_HEIGHT-1, :IMAGE_WIDTH-1, :] - x[:, :IMAGE_HEIGHT-1, 1:, :])\n",
    "        return backend.sum(backend.pow(a + b, TOTAL_VARIATION_LOSS_FACTOR))\n",
    "\n",
    "    def evaluate_loss_and_gradients(x):\n",
    "        x = x.reshape((1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "        outs = backend.function([xcombination], outputs)([x])\n",
    "        loss = outs[0]\n",
    "        gradients = outs[1].flatten().astype(\"float64\")\n",
    "        return loss, gradients\n",
    "\n",
    "    class Evaluator:\n",
    "\n",
    "        def loss(self, x):\n",
    "            loss, gradients = evaluate_loss_and_gradients(x)\n",
    "            self._gradients = gradients\n",
    "            return loss\n",
    "\n",
    "        def gradients(self, x):\n",
    "            return self._gradients\n",
    "    \n",
    "    content_img = np.asarray(content, dtype=\"float32\")\n",
    "    content_img = np.expand_dims(content_img, axis=0)\n",
    "    content_img[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "    content_img[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "    content_img[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "    content_img = content_img[:, :, :, ::-1]\n",
    "\n",
    "    style_image = np.asarray(style, dtype=\"float32\")\n",
    "    style_image = np.expand_dims(style_image, axis=0)\n",
    "    style_image[:, :, :, 0] -= IMAGENET_MEAN_RGB_VALUES[2]\n",
    "    style_image[:, :, :, 1] -= IMAGENET_MEAN_RGB_VALUES[1]\n",
    "    style_image[:, :, :, 2] -= IMAGENET_MEAN_RGB_VALUES[0]\n",
    "    style_image = style_image[:, :, :, ::-1]\n",
    "\n",
    "    xcontent = backend.variable(content_img)\n",
    "    xstyle = backend.variable(style_image)\n",
    "    xcombination = backend.placeholder((1, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "    input_tensor = backend.concatenate([xcontent,xstyle,xcombination], axis=0)\n",
    "    model = VGG16(input_tensor=input_tensor, include_top=False)\n",
    "\n",
    "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "    content_layer = 'block2_conv2'\n",
    "    layer_features = layers[content_layer]\n",
    "\n",
    "    content_image_features = layer_features[0, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "\n",
    "    loss = backend.variable(0.)\n",
    "    loss = loss + CONTENT_WEIGHT * content_loss(content_image_features,\n",
    "                                          combination_features)\n",
    "\n",
    "    style_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\"]\n",
    "    for layer_name in style_layers:\n",
    "        layer_features = layers[layer_name]\n",
    "        style_features = layer_features[1, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        style_loss = compute_style_loss(style_features, combination_features)\n",
    "        loss += (STYLE_WEIGHT / len(style_layers)) * style_loss\n",
    "\n",
    "    loss = loss + TOTAL_VARIATION_WEIGHT * total_variation_loss(xcombination)\n",
    "\n",
    "    outputs = [loss]\n",
    "    outputs += backend.gradients(loss, xcombination)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "\n",
    "    x = np.random.uniform(0, 255, (1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)) - 128.\n",
    "\n",
    "    for i in range(10):\n",
    "        x, loss, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.gradients, maxfun=20)\n",
    "        #print(\"Iteration %d completed with loss %d\" % (i, loss))\n",
    "\n",
    "    x = x.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))\n",
    "    x = x[:, :, ::-1]\n",
    "    x[:, :, 0] += IMAGENET_MEAN_RGB_VALUES[2]\n",
    "    x[:, :, 1] += IMAGENET_MEAN_RGB_VALUES[1]\n",
    "    x[:, :, 2] += IMAGENET_MEAN_RGB_VALUES[0]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(no_ofMasks=None):\n",
    "    count = 486\n",
    "    clean_paths = os.listdir('Clean/')\n",
    "    damaged_paths = os.listdir('Damaged/')\n",
    "    textures_paths = os.listdir('Textures/')\n",
    "    if no_ofMasks is None:\n",
    "        no_ofMasks = len(damaged_paths)\n",
    "    no_ofTextures = len(textures_paths)\n",
    "    for path_c in clean_paths[18:]:\n",
    "        clean_path = 'Clean/' + path_c\n",
    "        rng = np.random.default_rng()\n",
    "        random_masks = rng.choice(len(damaged_paths) , size = no_ofMasks, replace=False)\n",
    "        rng = np.random.default_rng()\n",
    "        random_textures = None\n",
    "        if no_ofMasks<=no_ofTextures:\n",
    "            random_textures = rng.choice(no_ofTextures , size = no_ofMasks, replace=False)\n",
    "        else:\n",
    "            random_textures = []\n",
    "            c = no_ofMasks\n",
    "            while c>0:\n",
    "                b = rng.choice(no_ofTextures , size = min(no_ofTextures,c), replace=False)\n",
    "                c -= no_ofTextures\n",
    "                random_textures += list(b)\n",
    "        for n1,i in enumerate(random_masks):\n",
    "            damaged_path = damaged_paths[i]\n",
    "            values = np.split(np.array(damaged_path[:-4].split('_'),np.int32) , 2)\n",
    "            mask , spots = get_mask_spots('Damaged/'+ damaged_path , values[0] , values[1])\n",
    "            if n1>int(len(random_masks)/2-1):\n",
    "                mask , spots = randomize_mask(mask , spots)\n",
    "            damaged1 = add_spots(clean_path , mask , spots)\n",
    "            style_path = 'Textures/' + textures_paths[random_textures[n1]]\n",
    "            style = cv2.imread(style_path)\n",
    "            style = cv2.resize(style , (768,512))\n",
    "            print(count+1)\n",
    "            damaged2 = nst(damaged1 , style)\n",
    "            print(count+1 , \"DONE\")\n",
    "            count += 1\n",
    "            cv2.imwrite('Dataset/clean/'+str(count)+'.jpg' , cv2.resize(cv2.imread(clean_path) , (768,512)))\n",
    "            cv2.imwrite('Dataset/damaged/'+str(count)+'.jpg' , damaged2)\n",
    "            cv2.imwrite('Dataset/masks/'+str(count)+'.jpg' , mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
