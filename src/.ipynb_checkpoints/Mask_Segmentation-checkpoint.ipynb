{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_paths , y_paths , batch , start):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    for i in range(start,min(len(x_paths) , start + batch)):\n",
    "        d = '../data/Dataset/damaged/' + x_paths[i]\n",
    "        d = cv2.imread(d)\n",
    "        m = '../data/Dataset/masks/' + y_paths[i]\n",
    "        m = cv2.imread(m , 0)\n",
    "        m = np.array(m == 255 , np.int32)\n",
    "        m = np.expand_dims(m , 2)\n",
    "        batch_x.append(d)\n",
    "        batch_y.append(m)\n",
    "    return np.array(batch_x)/255.0 , np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):\n",
    "    inputs = layers.Input(shape=img_size)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual]) \n",
    "        previous_block_activation = x  \n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])\n",
    "        previous_block_activation = x \n",
    "\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = get_model((512 , 768 , 3), 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_paths = os.listdir('../data/Dataset/damaged/')\n",
    "y_paths = os.listdir('../data/Dataset/masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 2500\n",
    "start = 0\n",
    "losses = []\n",
    "val_losses = []\n",
    "accuracy =[]\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    print(i+1)\n",
    "    x , y = get_batch(x_paths , y_paths , batch_size , start)\n",
    "    model.fit(x , y, epochs=1)#, validation_split = 0.2)\n",
    "    '''\n",
    "    losses.append(history.history['loss'][0])\n",
    "    val_losses.append(history.history['val_loss'][0])\n",
    "    accuracy.append(history.history['accuracy'][0])\n",
    "    val_accuracy.append(history.history['val_accuracy'][0])\n",
    "    if i % 100 ==0 and i > 0:\n",
    "        clear_output(wait = True)\n",
    "        plt.plot(losses, label='train')\n",
    "        plt.plot(val_losses, label='validation')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        plt.plot(accuracy, label='train')\n",
    "        plt.plot(val_accuracy, label='validation')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()'''\n",
    "    start += batch_size\n",
    "    if start >= len(x_paths):\n",
    "        start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(prob):\n",
    "    no = np.random.randint(len(x_paths))\n",
    "    img_path = '../data/Dataset/damaged/' + str(no)+'.jpg'\n",
    "    mask_path = '../data/Dataset/masks/' + str(no)+'.jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    maskr = cv2.imread(mask_path)\n",
    "    mask = model.predict(np.expand_dims(img , 0)/255.0)\n",
    "    mask = (mask > prob) *255.0\n",
    "    mask = np.reshape(mask , (mask.shape[1] , mask.shape[2])).astype('uint8')\n",
    "    plt.imshow(cv2.cvtColor(img , cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(maskr)\n",
    "    plt.show()\n",
    "    plt.imshow(mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dice_coef(y_true, y_pred_bin):\n",
    "    # shape of y_true and y_pred_bin: (height, width)\n",
    "    intersection = np.sum(y_true * y_pred_bin)\n",
    "    if (np.sum(y_true)==0) and (np.sum(y_pred_bin)==0):\n",
    "        return 1\n",
    "    return (2*intersection) / (np.sum(y_true) + np.sum(y_pred_bin))\n",
    "n=20\n",
    "x , y = get_batch(x_paths , y_paths , n , 0)#np.random.randint(885-n))\n",
    "single_dice_coef(y, model.predict(x) > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_model = model.to_json()\n",
    "with open('mask.json', 'w') as json_file:\n",
    "    json_file.write(json_model)\n",
    "model.save_weights('unet_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
